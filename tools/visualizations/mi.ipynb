{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.special import digamma as psi\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 加载CIFAR100数据集\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 将图像大小调整为ResNet50的输入尺寸\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 归一化\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR100(root='/home/fabien/Documents/project/2d/mdistiller/data/', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 加载预训练的ResNet50模型\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# 修改ResNet50的全连接层以匹配CIFAR100的类别数\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = torch.nn.Linear(num_ftrs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数以提取特征和logits\n",
    "# ResNet-50\n",
    "def extract_features_logits(model, dataloader):\n",
    "    model.eval()  # 设置为评估模式\n",
    "    all_features = []\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Extracting features and logits\"):\n",
    "            i += 1\n",
    "            if i > 20:\n",
    "                break\n",
    "            # 前向传播\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 提取倒数第二层的特征\n",
    "            features = model.avgpool(model.layer4(model.layer3(model.layer2(model.layer1(model.maxpool(model.relu(model.bn1(model.conv1(inputs))))))))).view(inputs.size(0), -1)\n",
    "            \n",
    "            all_features.extend(features.cpu().numpy())\n",
    "            all_logits.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return np.array(all_features), np.array(all_logits), np.array(all_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features and logits:   3%|▎         | 20/782 [01:20<51:10,  4.03s/it]\n"
     ]
    }
   ],
   "source": [
    "features, logits, labels = extract_features_logits(resnet50, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mutual information between features and labels: 8.385342349482837\n",
      "Estimated mutual information between logits and labels: 8.440498599482837\n"
     ]
    }
   ],
   "source": [
    "# 使用最近邻方法估计互信息的函数\n",
    "def estimate_mutual_information(k, data, labels):\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(data)\n",
    "    distances, indices = nbrs.kneighbors(data)\n",
    "    epsilon = distances[:, -1]\n",
    "    label_distances = labels[indices]\n",
    "    counts = (label_distances == labels[:, None]).sum(axis=1) - 1\n",
    "    mi_estimate = psi(k) - (counts/k).mean() + psi(len(data))\n",
    "    return mi_estimate\n",
    "\n",
    "# 估计特征与标签之间的互信息\n",
    "mi_features_labels = estimate_mutual_information(5, features, labels)\n",
    "print(f'Estimated mutual information between features and labels: {mi_features_labels}')\n",
    "\n",
    "# 估计logits与标签之间的互信息\n",
    "mi_logits_labels = estimate_mutual_information(5, logits, labels)\n",
    "print(f'Estimated mutual information between logits and labels: {mi_logits_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabien/anaconda3/envs/mdis2/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/fabien/anaconda3/envs/mdis2/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extracting features and logits:   3%|▎         | 20/782 [00:13<08:39,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated mutual information between features and labels: 8.544092349482836\n",
      "Estimated mutual information between logits and labels: 8.451904849482837\n"
     ]
    }
   ],
   "source": [
    "# MobileNetV2\n",
    "# 加载预训练的MobileNetV2模型\n",
    "mobilenet_v2 = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "class ModifiedMobileNetV2(torch.nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(ModifiedMobileNetV2, self).__init__()\n",
    "        self.features = original_model.features\n",
    "        self.classifier = original_model.classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        feature_maps = x\n",
    "        x = x.mean([2, 3])  # 全局平均池化\n",
    "        logits = self.classifier(x)\n",
    "        return feature_maps, logits\n",
    "\n",
    "modified_mobilenet_v2 = ModifiedMobileNetV2(mobilenet_v2)\n",
    "\n",
    "def extract_features_logits(model, dataloader):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Extracting features and logits\"):\n",
    "            i += 1\n",
    "            if i > 20:\n",
    "                break\n",
    "            feature_maps, logits = model(inputs)\n",
    "            all_features.extend(feature_maps.cpu().numpy())\n",
    "            all_logits.extend(logits.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return np.array(all_features), np.array(all_logits), np.array(all_labels)\n",
    "\n",
    "features, logits, labels = extract_features_logits(modified_mobilenet_v2, trainloader)\n",
    "\n",
    "def estimate_mutual_information(k, data, labels):\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(data.reshape(data.shape[0], -1))\n",
    "    distances, indices = nbrs.kneighbors(data.reshape(data.shape[0], -1))\n",
    "    epsilon = distances[:, -1]\n",
    "    label_distances = labels[indices]\n",
    "    counts = (label_distances == labels[:, None]).sum(axis=1) - 1\n",
    "    mi_estimate = psi(k) - (counts/k).mean() + psi(len(data))\n",
    "    return mi_estimate\n",
    "\n",
    "mi_features_labels = estimate_mutual_information(5, features, labels)\n",
    "print(f'Estimated mutual information between features and labels: {mi_features_labels}')\n",
    "\n",
    "mi_logits_labels = estimate_mutual_information(5, logits, labels)\n",
    "print(f'Estimated mutual information between logits and labels: {mi_logits_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabien/anaconda3/envs/mdis2/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/fabien/anaconda3/envs/mdis2/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG13_Weights.IMAGENET1K_V1`. You can also use `weights=VGG13_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Extracting features and logits:   3%|▎         | 20/782 [01:03<40:14,  3.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练的VGG13模型\n",
    "vgg13 = models.vgg13(pretrained=True)\n",
    "\n",
    "class ModifiedVGG13(torch.nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(ModifiedVGG13, self).__init__()\n",
    "        self.features = original_model.features\n",
    "        self.avgpool = original_model.avgpool\n",
    "        self.classifier = original_model.classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        feature_maps = x\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)  # 展平\n",
    "        logits = self.classifier(x)\n",
    "        return feature_maps, logits\n",
    "\n",
    "modified_vgg13 = ModifiedVGG13(vgg13)\n",
    "\n",
    "def extract_features_logits(model, dataloader):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Extracting features and logits\"):\n",
    "            feature_maps, logits = model(inputs)\n",
    "            i += 1\n",
    "            if i > 20:\n",
    "                break\n",
    "            all_features.extend(feature_maps.cpu().numpy())\n",
    "            all_logits.extend(logits.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return np.array(all_features), np.array(all_logits), np.array(all_labels)\n",
    "\n",
    "features, logits, labels = extract_features_logits(modified_vgg13, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1280, 512, 7, 7), (1280, 1000), (1280,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, logits.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_280634/515759758.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  logits = torch.tensor(logits)\n"
     ]
    }
   ],
   "source": [
    "# 假设features, logits, labels已经准备好\n",
    "# 需要将features从(1280, 512, 7, 7)展平为(1280, 512*7*7)\n",
    "\n",
    "features_flattened = torch.tensor(features).reshape(features.shape[0], -1)  # 展平特征\n",
    "logits = torch.tensor(logits)\n",
    "\n",
    "# 将labels从(1280,)扩展为(1280, 1)以便和特征、logits拼接\n",
    "labels_expanded = torch.tensor(labels).reshape(-1, 1).float()  # 假设labels是LongTensor，需要转换为FloatTensor用于拼接.\n",
    "\n",
    "joint_features = torch.cat((features_flattened, labels_expanded), dim=1)\n",
    "joint_logits = torch.cat((logits, labels_expanded), dim=1)\n",
    "\n",
    "# 为边缘分布创建打乱的labels\n",
    "shuffled_labels = labels[torch.randperm(labels.shape[0])]\n",
    "shuffled_labels_expanded = torch.tensor(shuffled_labels).reshape(-1, 1).float()\n",
    "\n",
    "marginal_features = torch.cat((features_flattened, shuffled_labels_expanded), dim=1)\n",
    "marginal_logits = torch.cat((logits, shuffled_labels_expanded), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# 定义MINE网络的输入维度\n",
    "features_dim = features_flattened.size(1) + 1  # 特征维度+标签维度\n",
    "logits_dim = logits.size(1) + 1  # logits维度+标签维度\n",
    "hidden_dim = 100  # 可以根据需要调整隐藏层维度\n",
    "\n",
    "# 重新定义MINE网络以匹配新的输入维度\n",
    "class MINE(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MINE, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# 创建两个MINE网络实例，一个用于特征和标签，一个用于logits和标签\n",
    "mine_net_features = MINE(features_dim)\n",
    "mine_net_logits = MINE(logits_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MI Features: -0.006370410323143005, MI Logits: -0.10478800535202026\n",
      "Epoch 10, MI Features: 0.10805314034223557, MI Logits: 0.0008315276354551315\n",
      "Epoch 20, MI Features: 0.1784161478281021, MI Logits: 0.0301041416823864\n",
      "Epoch 30, MI Features: 0.25960874557495117, MI Logits: 0.05236309766769409\n",
      "Epoch 40, MI Features: 0.3529484272003174, MI Logits: 0.07308085262775421\n",
      "Epoch 50, MI Features: 0.4553203284740448, MI Logits: 0.0926579087972641\n",
      "Epoch 60, MI Features: 0.5737002491950989, MI Logits: 0.11138467490673065\n",
      "Epoch 70, MI Features: 0.6998199820518494, MI Logits: 0.13082760572433472\n",
      "Epoch 80, MI Features: 0.8330408334732056, MI Logits: 0.15056318044662476\n",
      "Epoch 90, MI Features: 0.9693697690963745, MI Logits: 0.17055219411849976\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer_features = optim.Adam(mine_net_features.parameters(), lr=1e-4)\n",
    "optimizer_logits = optim.Adam(mine_net_logits.parameters(), lr=1e-4)\n",
    "\n",
    "def mutual_information_loss(t, et):\n",
    "    \"\"\"计算互信息损失\"\"\"\n",
    "    mi_loss = -(torch.mean(t) - torch.log(torch.mean(torch.exp(et))))\n",
    "    return mi_loss\n",
    "\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # 计算联合分布和边缘分布的网络输出\n",
    "    t_features = mine_net_features(joint_features)\n",
    "    et_features = mine_net_features(marginal_features)\n",
    "    loss_features = mutual_information_loss(t_features, et_features)\n",
    "    \n",
    "    t_logits = mine_net_logits(joint_logits)\n",
    "    et_logits = mine_net_logits(marginal_logits)\n",
    "    loss_logits = mutual_information_loss(t_logits, et_logits)\n",
    "\n",
    "    # 反向传播和优化\n",
    "    optimizer_features.zero_grad()\n",
    "    loss_features.backward()\n",
    "    optimizer_features.step()\n",
    "\n",
    "    optimizer_logits.zero_grad()\n",
    "    loss_logits.backward()\n",
    "    optimizer_logits.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, MI Features: {-loss_features.item()}, MI Logits: {-loss_logits.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
